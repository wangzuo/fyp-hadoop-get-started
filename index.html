<!DOCTYPE html>

<html>

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Getting Started with Hadoop</title>

  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <script src="./scripts/box2d.min.js"></script>
  <script src="./scripts/jquery-1.4.2.js"></script>
  <script src="./scripts/slide-presentation.js"></script>
  <script src="./scripts/slide-content.js"></script>
  <script src="./scripts/worker-lib.js"></script>

    <!--
    <script src="http://www.google.com/jsapi"></script>
  -->
  <link rel="stylesheet" href="css/slide-presentation.css">
  <link rel="stylesheet" href="css/slide-content.css">
    <!--
    <link href='http://fonts.googleapis.com/css?family=Molengo|Yanone+Kaffeesatz|Droid+Serif|OFL+Sorts+Mill+Goudy+TT|Inconsolata|Lobster|Cantal|Josefin+Sans+Std+Light|Reenie+Beanie' rel='stylesheet' type='text/css'>
  -->
  <style type="text/css">
    section img {
      max-width: 800px;
    }
  </style>
</head>

<body>
  <div class="presentation">

    <div class="slides">

      <div class="slide current">
        <section class="center">
          <div class="titleContent">
            <h2 class="titleTitle">
              <strong class="html5">Getting Started with Hadoop</strong>
            </h2>
            <p class="titleText">
              Wang Zuo<br>
              September 2012<br><br>
            </p>
          </div>
        </section>
      </div>

      <div class="slide far-future">
        <header>Big Data!</header>
        <section class="hbox">

          <ul>
            <li><strong>&ldquo;More data usually beats better algorithms&rdquo;</strong></li>
            <li>Data storage &amp; analysis challenge
              <ul>
                <li>Storage: data replication in case of failure</li>
                <li>Analysis: MapReduce programming model</li>
              </ul>
            </li>
          </ul>

        </section>
      </div>


<div class="slide far-future">
  <header>Parallel programming</header>
  <section class="hbox">
    <ul>
<li>serial vs. parallel</li>
<li>program processing broke into parts, each of which can be executed concurrently (different CPUs/cores)</li>
<li><strong>MASTER/SLAVE</strong> pattern</li>
</ul>

  </section>
  </div>

<div class="slide far-future">
  <header>MapReduce</header>
  <section class="hbox">
    <ul>
<li>Programming model for data processing</li>
<li><strong>Abstraction</strong> that allows engineers to perform simple computations while hiding the details of <strong>parallelization</strong>, <strong>data distribution</strong>, <strong>load balancing</strong> and <strong>fault tolerance</strong> in a library</li>
<li>Developed with Google to process large amounts of raw data</li>
<li><a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en/us/archive/mapreduce-osdi04.pdf">Dean, Jeff and Ghemawat, Sanjay. <strong>MapReduce: Simplified Data Processing on Large Clusters</strong></a></li>
</ul>

  </section>
</div>


<div class="slide far-future">
  <header>Programming Model</header>
  <section class="hbox">
    
<pre><code>
map     (k1, v1)        -&gt; list(k2, v2)
reduce  (k2, list(v2))  -&gt; list(v2)
</code></pre>


  </section>
</div>



<div class="slide far-future">
  <header>Word Count Example</header>
  <section class="hbox">
    
<pre><code>
map(String key, String value):
  // key: document name
  // value: document contents
  for each word w in value:
      EmitIntermediate(w, "1");

reduce(String key, Iterator values):
    // key: a word
    // values: a list of counts
    int result = 0;
    for each v in values:
        result += ParseInt(v);
    Emit(AsString(result));
</code></pre>
  </section>
</div>

<div class="slide far-future">
  <header>Execution</header>
  <section class="hbox">
    
<p><img src="http://www.dbthink.com/wp-content/uploads/2010/06//map_reduce_execution_overview.jpg" alt="image" /></p>

  </section>
</div>


<div class="slide far-future">
  <header><Word Count execution</header>
  <section class="hbox">
    
<p><img src="http://www.confusedcoders.com/wp-content/uploads/2012/08/wordcount.png" alt="image" /></p>

  </section>
</div>


<div class="slide far-future">
  <header>About the sorting</header>
  <section class="hbox">
    
<p>When a reduce worker has read all intermediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. If the amount of intermediate data is too large to fit in memory, an external sort is used.</p>

  </section>
</div>


<div class="slide far-future">
  <header>Apache Hadoop</header>
  <section class="hbox">
    <ul>
<li>Apache Hadoop</li>
<li><strong>Reliable shared storage</strong> and <strong>analysis system</strong>

<ul>
<li>Storage: Hadoop Distributed File System(HDFS)</li>
<li>Analysis: MapReduce</li>
</ul>
</li>
</ul>

<img src="http://pentahoadmin.files.wordpress.com/2010/08/hadoopelephant_rgb1.png">
  </section>
</div>


<div class="slide far-future">
  <header>MapReduce Execution in Hadoop</header>
  <section class="hbox">
    <ul>
<li>A single reduce task</li>
<li>Multiple reduce tasks</li>
<li>No reduce task</li>
</ul>


  </section>
</div>


<div class="slide far-future">
  <header>HDFS</header>
  <section class="hbox">
    ul>
<li>Hadoop Distributed File System</li>
<li>Distributed file system (network file system)</li>
</ul>

  </section>
</div>



<div class="slide far-future">
  <header>Hadoop Installation</header>
  <section class="hbox">
    
<h3>Java</h3>

<p>Sun Java on Ubuntu linux, Hadoop not compatible with open SDK, to install sun java on ubuntu linux, refer to <a href="https://github.com/flexiondotorg/oab-java6">oab-java6</a></p>

<h3>linux</h3>

<p>linux is the only supported production environment</p>

<pre><code>
$ tar xzf hadoop-x.y.z.tar.gz
$ export JAVA_HOME
$ export HADOOP_INSTALL
$ export PATH=$PATH:$HADOOP_INSTALL/bin
$ hadoop version
</code></pre>

<h3>mac</h3>

<p>only for development</p>

<pre><code>
brew install hadoop
</code></pre>
  </section>
</div>


<div class="slide far-future">
  <header>Hadoop Configuration</header>
  <section class="hbox">
    
<h3>Standalone (local) mode</h3>

<ul>
<li>no daemons</li>
<li>single JVM</li>
<li>development purpose</li>
</ul>


<h3>Pseudo-distributed mode</h3>

<ul>
<li>local machine</li>
<li>simulating a cluster on a small scale</li>
</ul>


<h3>Fully distrubted mode</h3>

<ul>
<li>cluster of machines</li>
</ul>


  </section>
</div>


<div class="slide far-future">
  <header>Hadoop configuration files</header>
  <section class="hbox">
    
<p> /usr/local/Cellar/hadoop/1.0.3/libexec/conf/</p>

<ul>
<li>hadoop-env.sh</li>
<li>core-site.xml</li>
<li>hdfs-site.xml</li>
<li>mapred-site.xml</li>
</ul>
  </section>
</div>


<div class="slide far-future">
  <header>Word Count with Hadoop</header>
  <section class="hbox">
    
<p><a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Mapper.html">Mapper Interface</a></p>

<pre><code>
  public class Mapper&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;
</code></pre>

<p><a href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/mapreduce/Reducer.html">Reducer Interface</a></p>

<pre><code>
  public class Reducer&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;
</code></pre>

<p><a href="http://hadoop.apache.org/docs/r0.20.2/api/org/apache/hadoop/mapreduce/Mapper.Context.html">Mapper.Content</a></p>

<pre><code>
  public class Mapper.Context extends MapContext&lt;KEYIN, VALUEIN, KEYOUT, VALUEOUT&gt;
</code></pre>
  </section>
</div>



<div class="slide far-future">
  <header>Java Code</header>
  <section class="hbox">
    
<p><a href="WordCount.java">WordCount.java</a></p>

<p><a href="http://en.wikipedia.org/wiki/Generics_in_Java">Java Generics</a></p>

<p><a href="http://docs.oracle.com/javase/tutorial/java/javaOO/nested.html">Java nested classes</a></p>

<p>Hadoop provides its own set of basic types optimized for network serialization</p>

<ul>
<li>LongWritable: Java Long</li>
<li>Text: Java String</li>
<li>IntWritable: Java Integer</li>
</ul>
  </section>
</div>


<div class="slide far-future">
  <header>Java Code</header>
  <section class="hbox">
    
<p><a href="http://hadoop.apache.org/docs/r0.20.1/api/org/apache/hadoop/mapreduce/Reducer.html">Reducer</a></p>

<ul>
<li><strong>Shuffle</strong>: The reducer copies the sorted output from each Mapper using HTTP across the network</li>
<li><strong>Sort</strong>: The framework merge sorts Reducer inputs by keys. The shuffle and sort phases occur simultaneously i.e. while outputs are being fetched they are merged.</li>
<li><strong>Reduce</strong>: Reducer.reduce() method called for each &lt;key, (collection of values)>; The output of the Reducer is not re-sorted.</li>
</ul>
  </section>
</div>


<div class="slide far-future">
  <header>Test Run</header>
  <section class="hbox">
    
<pre><code>
$ javac -classpath /path/to/hadoop-x.y.z/hadoop-core-x.y.z.jar WordCount.java
$ jar cvf WordCount.jar *.class
$ hadoop jar WordCount.jar WordCount wordcount/input wordcount/output
</code></pre>
  </section>
</div>



<div class="slide far-future">
  <header>Pseuco-Distributed Mode</header>
  <section class="hbox">
    
<pre><code>ssh-keygen -t rsa -P ""
cat $HOME/.ssh/id_rsa.pub &gt;&gt; $HOME/.ssh/authorized_keys
ssh localhost
</code></pre>

<p>core-site.xml</p>

<pre><code>&lt;?xml version="1.0"?&gt;
&lt;!-- core-site.xml --&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.default.name&lt;/name&gt;
        &lt;value&gt;hdfs://localhost/&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>hdfs-site.xml</p>

<pre><code>&lt;?xml version="1.0"?&gt; 
&lt;!-- hdfs-site.xml --&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;1&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>mapred-site.xml</p>

<pre><code>&lt;?xml version="1.0"?&gt;
&lt;!-- mapred-site.xml --&gt;
&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapred.job.tracker&lt;/name&gt;
        &lt;value&gt;localhost:8021&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

  </section>
</div>


<div class="slide far-future">
  <header>Execution</header>
  <section class="hbox">
    
<pre><code>$ clear /tmp/hadoop* (clear datanode)

$ hadoop namenode -format


$ start-all.sh
$ jps
$ ps ax | grep hadoop | wc -l
</code></pre>

<p>NameNode - http://localhost:50070</p>

<p>JobTracker - http://localhost:50030</p>

<pre><code>$ hadoop dfs -mkdir inputwords
$ hadoop dfs -put input inputwords

$ hadoop jar WordCount.jar WordCount inputwords outputwords
$ hadoopo fs -cat wordcount/output/part-r-0000
$ stop-all.sh
</code></pre>
  </section>
</div>



    </div> <!-- slides -->
  </div> <!-- presentation -->

</body>
</html>